[
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "",
    "text": "Random forest is resistant to overfitting, can find non linear correlations and run quickly yfinance lets us pull finace data quickly\n\n\nShow the code\n# Import libraries\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n\nwe will track a specific stock (^GSPC)\n\n\nShow the code\n#choose the stock\nsp500 =yf.Ticker(\"^GSPC\")\n\n#track it\nsp500 = sp500.history(period=\"max\")\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nDividends\nStock Splits\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n0.0\n0.0\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n0.0\n0.0\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n0.0\n0.0\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n0.0\n0.0\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n0.0\n0.0\n\n\n\n\n\n\n\nthis is time series data, behold\n\n\nShow the code\nsp500.index\n\n\nDatetimeIndex(['1927-12-30 00:00:00-05:00', '1928-01-03 00:00:00-05:00',\n               '1928-01-04 00:00:00-05:00', '1928-01-05 00:00:00-05:00',\n               '1928-01-06 00:00:00-05:00', '1928-01-09 00:00:00-05:00',\n               '1928-01-10 00:00:00-05:00', '1928-01-11 00:00:00-05:00',\n               '1928-01-12 00:00:00-05:00', '1928-01-13 00:00:00-05:00',\n               ...\n               '2025-05-12 00:00:00-04:00', '2025-05-13 00:00:00-04:00',\n               '2025-05-14 00:00:00-04:00', '2025-05-15 00:00:00-04:00',\n               '2025-05-16 00:00:00-04:00', '2025-05-19 00:00:00-04:00',\n               '2025-05-20 00:00:00-04:00', '2025-05-21 00:00:00-04:00',\n               '2025-05-22 00:00:00-04:00', '2025-05-23 00:00:00-04:00'],\n              dtype='datetime64[ns, America/New_York]', name='Date', length=24465, freq=None)\n\n\ngraph raise in price and time\n\n\nShow the code\nsp500.plot.line(y=\"Close\", use_index=True)\n\n\n\n\n\n\n\n\n\ndelete useless columns\n\n\nShow the code\ndel sp500[\"Dividends\"]\ndel sp500[\"Stock Splits\"]\n\n\ncreate a new column so we can guess tomorrow’s price\n\n\nShow the code\nsp500[\"Tomorrow\"] = sp500[\"Close\"].shift(-1)\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.760000\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n17.719999\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n17.549999\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n17.660000\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.500000\n\n\n\n\n\n\n\nmake target column to be whether the stock rose or fell. We only want to know if we should sell or buy\n\n\nShow the code\nsp500[\"Target\"] = (sp500[\"Tomorrow\"] &gt; sp500['Close']).astype(int)\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\nTarget\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.760000\n1\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n17.719999\n0\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n17.549999\n0\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n17.660000\n1\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.500000\n0\n\n\n\n\n\n\n\nthe market has changed fundamentally several times. lets remove all super old data to make predictions based on the now\n\n\nShow the code\nsp500 = sp500.loc[\"1990-01-01\":].copy()\nsp500\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\nTarget\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1990-01-02 00:00:00-05:00\n353.399994\n359.690002\n351.980011\n359.690002\n162070000\n358.760010\n0\n\n\n1990-01-03 00:00:00-05:00\n359.690002\n360.589996\n357.890015\n358.760010\n192330000\n355.670013\n0\n\n\n1990-01-04 00:00:00-05:00\n358.760010\n358.760010\n352.890015\n355.670013\n177000000\n352.200012\n0\n\n\n1990-01-05 00:00:00-05:00\n355.670013\n355.670013\n351.350006\n352.200012\n158530000\n353.790009\n1\n\n\n1990-01-08 00:00:00-05:00\n352.200012\n354.239990\n350.540009\n353.790009\n140110000\n349.619995\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2025-05-19 00:00:00-04:00\n5902.879883\n5968.609863\n5895.689941\n5963.600098\n4144010000\n5940.459961\n0\n\n\n2025-05-20 00:00:00-04:00\n5944.660156\n5953.060059\n5909.259766\n5940.459961\n4416850000\n5844.609863\n0\n\n\n2025-05-21 00:00:00-04:00\n5910.180176\n5938.370117\n5830.910156\n5844.609863\n5254250000\n5842.009766\n0\n\n\n2025-05-22 00:00:00-04:00\n5841.259766\n5878.080078\n5825.819824\n5842.009766\n5157050000\n5802.819824\n0\n\n\n2025-05-23 00:00:00-04:00\n5781.890137\n5829.509766\n5767.410156\n5802.819824\n4662820000\nNaN\n0\n\n\n\n\n8915 rows × 7 columns",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html#import-the-libraries-and-explaining-the-model",
    "href": "Machine_Learning/project1.html#import-the-libraries-and-explaining-the-model",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "",
    "text": "Random forest is resistant to overfitting, can find non linear correlations and run quickly yfinance lets us pull finace data quickly\n\n\nShow the code\n# Import libraries\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n\nwe will track a specific stock (^GSPC)\n\n\nShow the code\n#choose the stock\nsp500 =yf.Ticker(\"^GSPC\")\n\n#track it\nsp500 = sp500.history(period=\"max\")\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nDividends\nStock Splits\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n0.0\n0.0\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n0.0\n0.0\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n0.0\n0.0\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n0.0\n0.0\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n0.0\n0.0\n\n\n\n\n\n\n\nthis is time series data, behold\n\n\nShow the code\nsp500.index\n\n\nDatetimeIndex(['1927-12-30 00:00:00-05:00', '1928-01-03 00:00:00-05:00',\n               '1928-01-04 00:00:00-05:00', '1928-01-05 00:00:00-05:00',\n               '1928-01-06 00:00:00-05:00', '1928-01-09 00:00:00-05:00',\n               '1928-01-10 00:00:00-05:00', '1928-01-11 00:00:00-05:00',\n               '1928-01-12 00:00:00-05:00', '1928-01-13 00:00:00-05:00',\n               ...\n               '2025-05-12 00:00:00-04:00', '2025-05-13 00:00:00-04:00',\n               '2025-05-14 00:00:00-04:00', '2025-05-15 00:00:00-04:00',\n               '2025-05-16 00:00:00-04:00', '2025-05-19 00:00:00-04:00',\n               '2025-05-20 00:00:00-04:00', '2025-05-21 00:00:00-04:00',\n               '2025-05-22 00:00:00-04:00', '2025-05-23 00:00:00-04:00'],\n              dtype='datetime64[ns, America/New_York]', name='Date', length=24465, freq=None)\n\n\ngraph raise in price and time\n\n\nShow the code\nsp500.plot.line(y=\"Close\", use_index=True)\n\n\n\n\n\n\n\n\n\ndelete useless columns\n\n\nShow the code\ndel sp500[\"Dividends\"]\ndel sp500[\"Stock Splits\"]\n\n\ncreate a new column so we can guess tomorrow’s price\n\n\nShow the code\nsp500[\"Tomorrow\"] = sp500[\"Close\"].shift(-1)\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.760000\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n17.719999\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n17.549999\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n17.660000\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.500000\n\n\n\n\n\n\n\nmake target column to be whether the stock rose or fell. We only want to know if we should sell or buy\n\n\nShow the code\nsp500[\"Target\"] = (sp500[\"Tomorrow\"] &gt; sp500['Close']).astype(int)\nsp500.head()\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\nTarget\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1927-12-30 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.760000\n1\n\n\n1928-01-03 00:00:00-05:00\n17.760000\n17.760000\n17.760000\n17.760000\n0\n17.719999\n0\n\n\n1928-01-04 00:00:00-05:00\n17.719999\n17.719999\n17.719999\n17.719999\n0\n17.549999\n0\n\n\n1928-01-05 00:00:00-05:00\n17.549999\n17.549999\n17.549999\n17.549999\n0\n17.660000\n1\n\n\n1928-01-06 00:00:00-05:00\n17.660000\n17.660000\n17.660000\n17.660000\n0\n17.500000\n0\n\n\n\n\n\n\n\nthe market has changed fundamentally several times. lets remove all super old data to make predictions based on the now\n\n\nShow the code\nsp500 = sp500.loc[\"1990-01-01\":].copy()\nsp500\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\nTarget\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n1990-01-02 00:00:00-05:00\n353.399994\n359.690002\n351.980011\n359.690002\n162070000\n358.760010\n0\n\n\n1990-01-03 00:00:00-05:00\n359.690002\n360.589996\n357.890015\n358.760010\n192330000\n355.670013\n0\n\n\n1990-01-04 00:00:00-05:00\n358.760010\n358.760010\n352.890015\n355.670013\n177000000\n352.200012\n0\n\n\n1990-01-05 00:00:00-05:00\n355.670013\n355.670013\n351.350006\n352.200012\n158530000\n353.790009\n1\n\n\n1990-01-08 00:00:00-05:00\n352.200012\n354.239990\n350.540009\n353.790009\n140110000\n349.619995\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2025-05-19 00:00:00-04:00\n5902.879883\n5968.609863\n5895.689941\n5963.600098\n4144010000\n5940.459961\n0\n\n\n2025-05-20 00:00:00-04:00\n5944.660156\n5953.060059\n5909.259766\n5940.459961\n4416850000\n5844.609863\n0\n\n\n2025-05-21 00:00:00-04:00\n5910.180176\n5938.370117\n5830.910156\n5844.609863\n5254250000\n5842.009766\n0\n\n\n2025-05-22 00:00:00-04:00\n5841.259766\n5878.080078\n5825.819824\n5842.009766\n5157050000\n5802.819824\n0\n\n\n2025-05-23 00:00:00-04:00\n5781.890137\n5829.509766\n5767.410156\n5802.819824\n4662820000\nNaN\n0\n\n\n\n\n8915 rows × 7 columns",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html#train-the-model",
    "href": "Machine_Learning/project1.html#train-the-model",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "Train the Model",
    "text": "Train the Model\nSince this is time series data we cant use cross validation, which would do great here on our training set but terrible in the real world. This is because it ignores the time series nature of the data and will use future data to predict the past. This is leakage and will ruin the model\n\n\nShow the code\n# n_estimators is number of trees, higher is better, 100 is low but we want it to be quick\n# min_sample_split is a protection to obverfitting, higher number less acurate model\n# random_state is a seed\n\nclf = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)\n\ntrain = sp500.iloc[:-100]\ntest = sp500.iloc[-100:]  # this is just for the baseline split, will do a better split later\n\npredictors = [\"Close\",\"High\",\"Open\",\"Volume\",\"Low\"]\n\nclf.fit(train[predictors], train[\"Target\"])\n\n\nRandomForestClassifier(min_samples_split=100, random_state=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier(min_samples_split=100, random_state=1) \n\n\nLets look at the predictions\n\n\nShow the code\ninitial_predictions = clf.predict(test[predictors])\n\ninitial_predictions = pd.Series(initial_predictions, index = test.index)\n\ninitial_predictions\n\n\nDate\n2024-12-30 00:00:00-05:00    1\n2024-12-31 00:00:00-05:00    1\n2025-01-02 00:00:00-05:00    1\n2025-01-03 00:00:00-05:00    1\n2025-01-06 00:00:00-05:00    1\n                            ..\n2025-05-19 00:00:00-04:00    1\n2025-05-20 00:00:00-04:00    1\n2025-05-21 00:00:00-04:00    1\n2025-05-22 00:00:00-04:00    1\n2025-05-23 00:00:00-04:00    1\nLength: 100, dtype: int64\n\n\nSince the right answers are just as important as teh wrong answers we will use precision to judge this model\n\n\nShow the code\nprecision_score(test[\"Target\"], initial_predictions)\n\n\n0.5802469135802469\n\n\nSince this model has a 58% precision it is slightly better than randomly guessing, which is 50%\nLets compare the predictions (orange) to the actual results (blue)\n\n\nShow the code\n# axis=1 means treat each one as a column\ncombined = pd.concat([test[\"Target\"], initial_predictions], axis=1)\n\ncombined.plot()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ninitial_predictions.value_counts()\n\n\n1    81\n0    19\nName: count, dtype: int64",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html#backtesting",
    "href": "Machine_Learning/project1.html#backtesting",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "Backtesting",
    "text": "Backtesting\nLets start backtesting to see if it improves our model\nThis will take 10 years of data and train the model to guess the 11th year. Then it uses 11 years to predict the 12th, and so on.\n\n\nShow the code\n#define the functions\n\ndef predict(train, test, predictors, model):\n  model.fit(train[predictors], train[\"Target\"])\n  predictions = model.predict(test[predictors])\n  predictions = pd.Series(predictions, index = test.index, name=\"Predictions\")\n  combined = pd.concat([test[\"Target\"], predictions], axis=1)\n  return combined\n\n# start=2500 is 10 years of data\n# Step = 250 is a year\n\ndef backtest(data, model, predictors, start=2500, step=250):\n  # list of data frames for a single year\n  all_predictions = []\n\n  for i in range(start, data.shape[0], step):\n    train = data.iloc[0:i].copy()\n    test = data.iloc[i:(i+step)].copy()\n    predictions = predict(train, test, predictors, model)\n    all_predictions.append(predictions)\n\n  return pd.concat(all_predictions)\n\n\n\n\nShow the code\n# use our data, model and chosen columns, per the backtest method to get new predictions\npredictions = backtest(sp500, clf, predictors)\n\npredictions.Predictions.value_counts()\n\n\nPredictions\n0    3726\n1    2689\nName: count, dtype: int64\n\n\n\n\nShow the code\npredictions.Target.value_counts() / predictions.shape[0]\n\n\nTarget\n1    0.536243\n0    0.463757\nName: count, dtype: float64\n\n\nThese results are much more varied than the last that were 85% stock raise predictions. These predictions are only 53% in the positive\n\n\nShow the code\nprecision_score(predictions[\"Target\"],predictions[\"Predictions\"])\n\n\n0.5232428412049089\n\n\nEven though our answers are much more varied, the precision is actually lower",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html#creating-new-features",
    "href": "Machine_Learning/project1.html#creating-new-features",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "Creating new Features",
    "text": "Creating new Features\nSince our model is only running on what the stocks sold at and when it would be best to make new features. We will model a few off of horizons that stock traders use to predict the market themselves\nWe will look at the trends for the last 2 days, trading week, 3 months, year and 4 years\n\n\nShow the code\n# these are useful days that human analysists use to look at the data\n# we calculyte the mean close price for the last 2 days, 5 days (a trading week), the last 3 months or so (60), last year (250) and last 4 years (1000)\nhorizons = [2,5,60,250,1000]\nnew_predictors = []\n\nfor horizon in horizons:\n  rolling_averages = sp500.rolling(horizon).mean()\n\n  ratio_column = f\"Close_{horizon}\"\n  sp500[ratio_column] = sp500.Close / rolling_averages.Close\n\n  trend_column = f\"Trend_{horizon}\"\n  sp500[trend_column] = sp500.shift(1).rolling(horizon).sum()[\"Target\"]\n\n  new_predictors += [ratio_column, trend_column]\n\n\nThis creates 4 years at the start that do not have prior data to use and are now filled with N/As, lets cut them. Notice how the start data is now different.\n\n\nShow the code\nsp500 = sp500.dropna()\nsp500\n\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\nTomorrow\nTarget\nClose_2\nTrend_2\nClose_5\nTrend_5\nClose_60\nTrend_60\nClose_250\nTrend_250\nClose_1000\nTrend_1000\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1993-12-14 00:00:00-05:00\n465.730011\n466.119995\n462.459991\n463.059998\n275050000\n461.839996\n0\n0.997157\n1.0\n0.996617\n1.0\n1.000283\n32.0\n1.028047\n127.0\n1.176082\n512.0\n\n\n1993-12-15 00:00:00-05:00\n463.059998\n463.690002\n461.839996\n461.839996\n331770000\n463.339996\n1\n0.998681\n0.0\n0.995899\n1.0\n0.997329\n32.0\n1.025151\n126.0\n1.172676\n512.0\n\n\n1993-12-16 00:00:00-05:00\n461.859985\n463.980011\n461.859985\n463.339996\n284620000\n466.380005\n1\n1.001621\n1.0\n0.999495\n2.0\n1.000311\n32.0\n1.028274\n127.0\n1.176163\n513.0\n\n\n1993-12-17 00:00:00-05:00\n463.339996\n466.380005\n463.339996\n466.380005\n363750000\n465.850006\n0\n1.003270\n2.0\n1.004991\n3.0\n1.006561\n32.0\n1.034781\n128.0\n1.183537\n514.0\n\n\n1993-12-20 00:00:00-05:00\n466.380005\n466.899994\n465.529999\n465.850006\n255900000\n465.299988\n0\n0.999431\n1.0\n1.003784\n2.0\n1.005120\n32.0\n1.033359\n128.0\n1.181856\n513.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2025-05-16 00:00:00-04:00\n5929.089844\n5958.620117\n5907.359863\n5958.379883\n4850850000\n5963.600098\n1\n1.003490\n2.0\n1.009942\n5.0\n1.061316\n34.0\n1.046013\n146.0\n1.270287\n532.0\n\n\n2025-05-19 00:00:00-04:00\n5902.879883\n5968.609863\n5895.689941\n5963.600098\n4144010000\n5940.459961\n0\n1.000438\n2.0\n1.006751\n5.0\n1.062402\n35.0\n1.046444\n146.0\n1.270919\n533.0\n\n\n2025-05-20 00:00:00-04:00\n5944.660156\n5953.060059\n5909.259766\n5940.459961\n4416850000\n5844.609863\n0\n0.998056\n1.0\n1.001023\n4.0\n1.058414\n35.0\n1.041921\n145.0\n1.265517\n532.0\n\n\n2025-05-21 00:00:00-04:00\n5910.180176\n5938.370117\n5830.910156\n5844.609863\n5254250000\n5842.009766\n0\n0.991867\n0.0\n0.986466\n3.0\n1.041678\n35.0\n1.024734\n144.0\n1.244662\n531.0\n\n\n2025-05-22 00:00:00-04:00\n5841.259766\n5878.080078\n5825.819824\n5842.009766\n5157050000\n5802.819824\n0\n0.999778\n0.0\n0.988527\n2.0\n1.041568\n34.0\n1.023894\n144.0\n1.243674\n530.0\n\n\n\n\n7914 rows × 17 columns",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html#new-model",
    "href": "Machine_Learning/project1.html#new-model",
    "title": "Stock Price Trend Prediction with Portfolio Optimization",
    "section": "New Model",
    "text": "New Model\nOur last model had low parameters because we wanted it to run quickly. Lets make a better model now\n\n\nShow the code\nnew_model = RandomForestClassifier(n_estimators=200, min_samples_split=50,random_state=42)\n\n\nLets also change the predictions. Lets set it so instead of guessing whether it raises or lowers it should guess the probability that it was raise. Then we only accept answers that have a 60% change of raising\n\n\nShow the code\ndef predict(train, test, predictors, model):\n  new_model.fit(train[predictors], train[\"Target\"])\n\n  predictions = model.predict_proba(test[predictors])[:,1] # Predict_proba returns probability that row equal 1 or 0 as opposed to just getting a 1 or 0. Second column of this is that stock price goes up\n  predictions[predictions &gt;= .6] =1 # this is a custom threshold. It needs a 60% chance to output a 1\n  predictions[predictions &lt; .6] =0\n\n  predictions = pd.Series(predictions, index = test.index, name=\"Predictions\")\n  combined = pd.concat([test[\"Target\"], predictions], axis=1)\n\n  return combined\n\n\n\n\nShow the code\npredictions = backtest(sp500, new_model, new_predictors)  # you will notice we have stopped using the original predictors, like Open and Close. These are absolute numbers and not very informative to our model\n\npredictions.Predictions.value_counts()\n\n\nPredictions\n0.0    4591\n1.0     823\nName: count, dtype: int64",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ethan Saline",
    "section": "",
    "text": "Welcome to my Portfolio\n\n\n\n Back to top"
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Ethan Saline’s CV",
    "section": "",
    "text": "Data Science Student\n\nLinkedin | Github\n\n\n\nMachine Learning: Tensorflow, Optimizing Models, Pipelining Data Science: Pandas, NumPy, SciPy Data Visualization: GGPlot, Matplotlib, Seaborn Big Data & Databases: MySQL, SQLite Spoken Languages: Portuguese (Fluent), English (Native) Other: JIRA, CI/CD\n\n\n\nBYUI Math/Data Science Lab - Tutor SEPTEMBER 2024 - PRESENT Assisted students in developing problem-solving skills and mathematical reasoning focused in Calculus Church of Jesus Christ of Latter-Day Saints, São Paulo - Missionary OCTOBER 2021 - OCTOBER 2023 Developed fluency in Portuguese and cross-cultural communication skills.\n\n\n\nBrigham Young University Idaho - Data Science Major, Statistics Minor APRIL 2024 - OCTOBER 2026\n\n\n\nBrigham Young University Idaho, OCTOBER 2026 Machine Learning\nStanford University, FEBRUARY 2024 Machine Learning Advanced Learning Algorithms Unsupervised Learning, Recommenders, Reinforcement Learning Supervised Machine Learning: Regression and Classification"
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Ethan Saline’s CV",
    "section": "",
    "text": "Machine Learning: Tensorflow, Optimizing Models, Pipelining Data Science: Pandas, NumPy, SciPy Data Visualization: GGPlot, Matplotlib, Seaborn Big Data & Databases: MySQL, SQLite Spoken Languages: Portuguese (Fluent), English (Native) Other: JIRA, CI/CD"
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Ethan Saline’s CV",
    "section": "",
    "text": "BYUI Math/Data Science Lab - Tutor SEPTEMBER 2024 - PRESENT Assisted students in developing problem-solving skills and mathematical reasoning focused in Calculus Church of Jesus Christ of Latter-Day Saints, São Paulo - Missionary OCTOBER 2021 - OCTOBER 2023 Developed fluency in Portuguese and cross-cultural communication skills."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Ethan Saline’s CV",
    "section": "",
    "text": "Brigham Young University Idaho - Data Science Major, Statistics Minor APRIL 2024 - OCTOBER 2026"
  },
  {
    "objectID": "resume.html#certifications",
    "href": "resume.html#certifications",
    "title": "Ethan Saline’s CV",
    "section": "",
    "text": "Brigham Young University Idaho, OCTOBER 2026 Machine Learning\nStanford University, FEBRUARY 2024 Machine Learning Advanced Learning Algorithms Unsupervised Learning, Recommenders, Reinforcement Learning Supervised Machine Learning: Regression and Classification"
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Sensor Fusion and Predictive Maintenance for Autonomous Aerial Vehicles using ML Pipelines and Stochastic Nonlinear Optimization",
    "section": "",
    "text": "Paste in a template\nsimulate a UAV (drone) environment with multiple sensors (e.g., accelerometer, gyroscope, temperature), fuse this data, predict component wear/failure, and optimize maintenance schedules.\nSimulate Sensor Data\n\n\nShow the code\nimport numpy as np\nimport pandas as pd\n\n# Sets the random seed so the results are reproducible every time run the code\nnp.random.seed(0)\n\ntime = np.arange(0, 1000)\n\ndata = pd.DataFrame({\n    'time': time,\n\n    #sine wave signal plus random noise (simulated sensor reading)\n    'accelerometer': np.sin(time * 0.01) + np.random.normal(0, 0.1, len(time)),\n\n    # cosine wave signal plus noise (another sensor)\n    'gyroscope': np.cos(time * 0.01) + np.random.normal(0, 0.1, len(time)),\n\n    # slowly increasing linear trend plus noise (simulated thermal sensor)\n    'temperature': 30 + 0.01 * time + np.random.normal(0, 0.5, len(time)),\n})\n\ndata.head()\n\n\n\n\n\n\n\n\n\ntime\naccelerometer\ngyroscope\ntemperature\n\n\n\n\n0\n0\n0.176405\n1.055596\n29.233539\n\n\n1\n1\n0.050016\n1.089197\n29.154015\n\n\n2\n2\n0.117872\n0.957569\n30.043068\n\n\n3\n3\n0.254085\n1.010021\n29.550813\n\n\n4\n4\n0.226745\n1.022005\n29.999594\n\n\n\n\n\n\n\nCreate a Health Score Label\n\n\nShow the code\n# Create a health score that degrades over time\ndata['health_score'] = 1 - (time / max(time)) + np.random.normal(0, 0.05, len(time))\ndata['health_score'] = data['health_score'].clip(0, 1)\n\n\nBuild a Scikit-Learn ML Pipeline\n\n\nShow the code\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\nX = data[['accelerometer', 'gyroscope', 'temperature']]\ny = data['health_score']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', RandomForestRegressor(n_estimators=100)),\n])\npipeline.fit(X_train, y_train)\n\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('model', RandomForestRegressor())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFittedPipeline(steps=[('scaler', StandardScaler()),\n                ('model', RandomForestRegressor())]) StandardScaler?Documentation for StandardScalerStandardScaler() RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor() \n\n\nEvaluate the Model\n\n\nShow the code\nfrom sklearn.metrics import mean_squared_error\n\npreds = pipeline.predict(X_test)\nmse = mean_squared_error(y_test, preds)\nprint(f\"Test MSE: {mse:.4f}\")\n\n\nTest MSE: 0.0030\n\n\nStochastic Nonlinear Optimization for Maintenance Scheduling\nGoal: Minimize maintenance cost while keeping the average health score above a threshold.\nDefines a mock cost function that:\nTakes a maintenance interval (days).\nSimulates linear degradation from 1 to 0 over 1000 units.\nChecks how many times the health at maintenance points is below 0.5 (bad health), penalizing such schedules heavily.\nReturns total cost balancing maintenance frequency and penalties.\n\n\nShow the code\nfrom scipy.optimize import differential_evolution\n\n# Mock cost function\ndef maintenance_cost(schedule):\n    intervals = schedule[0]\n    if intervals &lt;= 0: return 1e6\n    simulated_health = 1 - np.linspace(0, 1, 1000)\n    maintenance_penalty = np.sum(simulated_health[::int(intervals)] &lt; 0.5)\n    return intervals + 100 * maintenance_penalty\n\nresult = differential_evolution(maintenance_cost, bounds=[(1, 100)])\nprint(f\"Optimal maintenance interval: {result.x[0]:.2f}\")\n\n\nOptimal maintenance interval: 91.32\n\n\nVisualize Everything\n\n\nShow the code\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,4))\nplt.plot(data['time'], data['health_score'], label='Health Score')\nplt.xlabel(\"Time\"); plt.ylabel(\"Score\")\nplt.title(\"Simulated UAV Component Health\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  }
]